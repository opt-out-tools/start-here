# OOT tools and vision

## Vision

At **Opt Out Tools**, we’re building tools to help all female-identifying
people with something to say, trust that they can take part in healthy online
discussion safely. We want social media platforms to be a **respectful**
place where any can comment without fear of viscous retaliation, **inclusive**
so all voices can flourish and **safe** so no person has to worry about what
happens after they switch off their laptop. We want the social networks to be
better for all.  We want to achieve this by building tools and an organisation
that with these values and consent, privacy and transparency at its core.

## Tools

### The Opt Out browser extension

Our browser extension is designed to hide misogyny from an individual's Twitter
feed. However we are consent and not censorship-focused. We’re designing our
browser extension to have a local instance of the model that users can supply
feedback to. By giving the individual control over what they do and don’t see
whilst keeping their data private and upholding their safety, we hope to show
them that their voices can be heard online without traumatizing consequences.

### The OOT website

Our website aims to support female-identifying getting their voices back
and sustain the movement. Currently the website is only informative about
Opt Out Tools.  However, inspired by [HarassMap](https://harassmap.org/ar),
an Egyptian based NGO that allows people to submit reports of physical
 harassment which are displayed online on a map, our website will allow an
individual to anonymously submit details of their harassment. This data
will be stored, studied and feed the models that our other tools use, for
example the browser extension. Our website will transparently show details
of the usage statistics of the tools and show female-identifying clearly
how their participation by submitting their reports is helping to fuel the
movement and show our "antidote to silicon valley KPIs”. Our long-term
goal is to display a “virtual” harass map on our website, showing which
communities on your selected social media platform are misogynistic or
sexually aggressive or just downright abusive, enabling female-identifying
to navigate the murky waters of online society as best they can.

### The OOT activism

We’re holding workshops that give female-identifying people a chance to meet
and share their experiences online. By doing this we not only give much needed
support to these people but allow them to come together and in doing so, act in
a form of protest. By helping to form this community, it helps us identify
needed technical infrastructure and ensures that our tools are fit for purpose
enabling our tech to be as community-driven as possible.

We’re also holding workshops and hackathons to develop our “antidote to silicon
valley KPIs": KPIs that try to measure diversity, inclusivity and health of
online conversation. Current metrics of participation such as no. of shares,
no. of clicks etc. have ensured that the social media tech giants live in the
pockets of most people on the planet. But these simple metrics of participation
don’t tell the full story. We want to do it differently.

### The OOT research

Our tech is here to solve real-world problems. It's vital to us that we compile
and understand the latest research around online misogyny to inform our
technical decisions.

We're designing a research roadmap which will be used to compile research
about many aspects of online life. Our initial focus shall be on online
misogyny, how it is currently defined by various actors, the cause and
effects and what online misogyny means to Opt Out Tools.

As our research grows we will widen our focus to look into ethical AI and
content moderation online, what is currently being done in these spaces and
how we can help or do it better.


### The OOT AI

Language is incredibly nuanced. Our strategy is to develop a misogyny model
that removes misogyny targeted at a particular group of female-identifying
people being harassed online. By initially targeting our protection to a
specific group of people, we will improve the accuracy of our model, ensuring
that we remove what is truly misogynistic to this group and nothing else. As we
better understand online misogyny and how to model it we will improve our model
to have an increased range of groups whom our tool is of use to.

Currently we are focusing on Twitter and using Natural Language Processing to
understand the sentiment of a tweet. However this is a very simple model of how
language works. Language has content, context, is part of a conversation and
has meaning embedded in the words. To capture this and make our machine
learning models as precise as possible, we will eventually include network
analysis, computational linguistics and other techniques, so that we are as
sure as we can be that the comment is misogynistic.

Also it is important to state here our commitment to understanding the biases
and implications of the modeling that we are doing. We will also be looking
into fairness metrics, dialect identification and model bias to understand and
communicate the limitations of our work. We understand that misogyny sounds
different in different dialects or social groups, and our model should
understand that to avoid potential biases against any particular group of
people.
